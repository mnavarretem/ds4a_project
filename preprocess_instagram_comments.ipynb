{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "from progressbar import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from offcorss_functions.data_exploring_functions import *\n",
    "from offcorss_functions.classification_functions import *"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Define functions for text processing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import nltk  \n",
    "from nltk.corpus import stopwords  \n",
    "from nltk import word_tokenize  \n",
    "from nltk.stem import SnowballStemmer  \n",
    "from string import punctuation  \n",
    "from progressbar import ProgressBar\n",
    "\n",
    "# inicializar el extractor de raices lexicales\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "# inicializar la lista de palabras ignoradas \n",
    "non_words = list(punctuation)  \n",
    "# agregar a la lista los signos de apertura y los digitos [1-9]\n",
    "non_words.extend(['¬ø', '¬°'])  \n",
    "non_words.extend(map(str,range(10)))\n",
    "\n",
    "# funcion de extraccion de raices lexicales\n",
    "def stem(word):\n",
    "    return stemmer.stem(word)\n",
    "\n",
    "# funcion de extraccion de raices lexicales sobre una lista\n",
    "def stem_tokens(tokens):  \n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stem(item))\n",
    "    return stemmed\n",
    "\n",
    "# stop words should be updated to accept important words in our context (mostly for bigrams and trigrams)\n",
    "nostopwords  = ['no','muy','pero','eso']\n",
    "stopWords_ls = stopwords.words(\"spanish\")\n",
    "stopWords_ls = [word for word in stopWords_ls if word not in nostopwords]\n",
    "\n",
    "def words_to_ngrams(words, n, sep=\" \"):\n",
    "    ngrams = [sep.join(words[i:i+n]) for i in range(len(words)-n+1)]\n",
    "    return  ngrams\n",
    "\n",
    "def get_unique_tokens(comment_ls):\n",
    "\n",
    "    words_ls = []\n",
    "    \n",
    "    for text in comment_ls:\n",
    "        text  = \" \".join(re.findall(\"[a-zA-Z]+\", text))\n",
    "        words =  word_tokenize(text)\n",
    "        words = [word for word in words if word not in stopWords_ls]\n",
    "        \n",
    "        words_ls.append(list(set(words)))\n",
    "        \n",
    "    words_ls = [item for sublist in words_ls for item in sublist]    \n",
    "     \n",
    "    return list(set(words_ls))\n",
    "\n",
    "def get_tokenized(text):\n",
    "    words =  word_tokenize(text)\n",
    "    #words = [str.strip(word) for word in words if word not in stopWords_ls]\n",
    "    words = [str.strip(word) for word in words if word not in stopWords_ls]\n",
    "    #word = re.compile('\\w+').findall(word)\n",
    "    # get ngrams\n",
    "    ugrams = words_to_ngrams(words,1)\n",
    "    bgrams = words_to_ngrams(words,2)\n",
    "    tgrams = words_to_ngrams(words,3)\n",
    "    \n",
    "    ngrams = [ugrams,bgrams,tgrams]\n",
    "    \n",
    "    return  [item for sublist in ngrams for item in sublist]\n",
    "\n",
    "# Define features for classification\n",
    "def get_comment_features(test_comment):\n",
    "\n",
    "    test_comment = test_comment.replace(\" . \", \" \").replace(\" , \", \" \").replace(\" .\", \"\")\n",
    "\n",
    "    tokens = get_tokenized(test_comment)\n",
    "    #print(test_comment)\n",
    "    tokens = stem_tokens(tokens)\n",
    "\n",
    "    elem_scores = []\n",
    "    scores_vals = []\n",
    "\n",
    "    for cur_word in tokens:\n",
    "        if cur_word in known_words['stem'].values:\n",
    "            element  = known_words[known_words['stem'] == cur_word]\n",
    "            cur_score = element.score.values[0] \n",
    "        else:\n",
    "            cur_score = 0\n",
    "\n",
    "        elem_scores.append((cur_word,cur_score))\n",
    "        scores_vals.append(cur_score)\n",
    "\n",
    "    if len(scores_vals) > 0 :   \n",
    "        features_comment = [sum(scores_vals) / len(scores_vals),sum(scores_vals),len(scores_vals), min(scores_vals), max(scores_vals)]\n",
    "    else:\n",
    "        features_comment = [0,0,0,0,0]\n",
    "        \n",
    "    #print(features_comment)\n",
    "    #elem_scores\n",
    "    \n",
    "    return features_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open lexical dictionary\n",
    "products_file  = 'offcorss_products.csv'\n",
    "products_words = pd.read_csv(products_file).drop(columns = 'Unnamed: 0')\n",
    "\n",
    "# Open file for classification\n",
    "classifier_file =\"./classifier.pickle\"\n",
    "\n",
    "# Open lexical dictionary\n",
    "known_words = pd.read_csv('./offcorss_functions/OFFCORSS_lexicon.csv')\n",
    "\n",
    "f         = open(classifier_file, 'rb')\n",
    "logit_fit = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#File names and base path.\n",
    "base_datapath = 'C:\\\\Users\\\\sapmn3\\\\Database\\\\OFFCORSS\\\\data\\\\OFFCORSS_instagram'\n",
    "file_list = ['instagram_responses',\n",
    "            ]\n",
    "\n",
    "data_nps = []\n",
    "for cur_file in file_list:\n",
    "    cur_path = os.path.join(base_datapath, cur_file + '.csv')\n",
    "    cur_data = pd.read_csv(cur_path)\n",
    "    cur_data['time'] = pd.to_datetime(cur_data['time'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "    cur_data['time'] = cur_data['time'].dt.date\n",
    "    if len(data_nps) == 0:\n",
    "        data_comments = cur_data\n",
    "    else:\n",
    "        data_comments = pd.concat([data_nps, cur_data], axis=0)\n",
    "        \n",
    "#use lower letters to the comment column\n",
    "data_comments = data_comments.drop(columns = 'Unnamed: 0')\n",
    "data_comments['text'] = data_comments['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "data_responses = data_comments.reset_index(drop = True)\n",
    "\n",
    "vt_comment = []\n",
    "vt_tokens  = []\n",
    "vt_products= np.empty((0,len(products_words)), int)\n",
    "\n",
    "vt_mean    = []\n",
    "vt_sum     = []\n",
    "vt_size    = []\n",
    "vt_min     = []\n",
    "vt_max     = []\n",
    "vt_sentim  = []\n",
    "\n",
    "\n",
    "products_stm = stem_tokens(products_words.products)\n",
    "nm_lenData   = len(data_responses)\n",
    "\n",
    "pbar = ProgressBar()\n",
    "\n",
    "for idx in pbar(range(0,nm_lenData)):    \n",
    "    \n",
    "    # Get comment\n",
    "    cur_comm = data_responses.loc[idx,['text']].values[0]\n",
    "    \n",
    "    # Get tokenized comment\n",
    "    tokens, words = get_comment_tokens(cur_comm)\n",
    "    \n",
    "    # get products array\n",
    "    product_inComments = np.in1d(products_stm, stem_tokens(words), assume_unique=True)\n",
    "    product_inComments = product_inComments.astype(int) \n",
    "    product_inComments = product_inComments.reshape(1, len(products_words))\n",
    "\n",
    "      \n",
    "    # get classifier features    \n",
    "    features_comment = get_comment_features(cur_comm,known_words)\n",
    "    \n",
    "    nm_mean = features_comment[0]\n",
    "    nm_sum  = features_comment[1]\n",
    "    nm_size = features_comment[2]\n",
    "    nm_min  = features_comment[3]\n",
    "    nm_max  = features_comment[4]\n",
    "    \n",
    "    # append classifier features\n",
    "    vt_comment.append(cur_comm)\n",
    "    vt_mean.append(nm_mean)\n",
    "    vt_sum.append(nm_sum)\n",
    "    vt_size.append(nm_size)\n",
    "    vt_min.append(nm_min)\n",
    "    vt_max.append(nm_max)\n",
    "    \n",
    "    # append comments tokens and products\n",
    "    vt_tokens.append(tokens)\n",
    "    vt_products = np.append(vt_products, product_inComments, axis=0)\n",
    "    \n",
    "    \n",
    "    \n",
    "features_df = pd.DataFrame({'comment':vt_comment,'mean':vt_mean,'sum':vt_sum,'size':vt_size,\n",
    "                            'min':vt_min,'max':vt_max})\n",
    "\n",
    "comments_df = pd.DataFrame({'comment':vt_comment,'tokens':vt_tokens})\n",
    "products_df = pd.DataFrame(vt_products, columns = products_words.products)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>mean</th>\n",
       "      <th>sum</th>\n",
       "      <th>size</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>Intercept</th>\n",
       "      <th>score</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>as√≠ es un d√≠a para disfrutar  sana mente y con...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.614808</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buenos d√≠as que precio tienen?</td>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.875</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.619522</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>üéä</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.448265</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hermosa mi sheshe</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.992207</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cuanto cuesta el vestido de manga larga talla 14</td>\n",
       "      <td>-0.020833</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>0.250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.262286</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33483</th>\n",
       "      <td>@tina.benjumea üåü todos los tapabocas tienen un...</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>1.875</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.560458</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33484</th>\n",
       "      <td>@anil_rizo üíõ todos los tapabocas tienen un val...</td>\n",
       "      <td>0.022917</td>\n",
       "      <td>1.375</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.486015</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33485</th>\n",
       "      <td>üíõüíõ @paopao.martinezfigueroa  todos los tapaboc...</td>\n",
       "      <td>0.022917</td>\n",
       "      <td>1.375</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.486015</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33486</th>\n",
       "      <td>@contreraszarateyamileth ‚òÄÔ∏è‚òÄÔ∏è todos los tapabo...</td>\n",
       "      <td>0.022917</td>\n",
       "      <td>1.375</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.486015</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33487</th>\n",
       "      <td>@laer1217  hola!!! todos los tapabocas tienen ...</td>\n",
       "      <td>0.023148</td>\n",
       "      <td>1.250</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.477935</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33488 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment      mean    sum  \\\n",
       "0      as√≠ es un d√≠a para disfrutar  sana mente y con...  0.066667  1.000   \n",
       "1                         buenos d√≠as que precio tienen?  0.097222  0.875   \n",
       "2                                                      üéä  0.000000  0.000   \n",
       "3                                      hermosa mi sheshe  0.333333  1.000   \n",
       "4       cuanto cuesta el vestido de manga larga talla 14 -0.020833 -0.375   \n",
       "...                                                  ...       ...    ...   \n",
       "33483  @tina.benjumea üåü todos los tapabocas tienen un...  0.031250  1.875   \n",
       "33484  @anil_rizo üíõ todos los tapabocas tienen un val...  0.022917  1.375   \n",
       "33485  üíõüíõ @paopao.martinezfigueroa  todos los tapaboc...  0.022917  1.375   \n",
       "33486  @contreraszarateyamileth ‚òÄÔ∏è‚òÄÔ∏è todos los tapabo...  0.022917  1.375   \n",
       "33487  @laer1217  hola!!! todos los tapabocas tienen ...  0.023148  1.250   \n",
       "\n",
       "       size    min    max  Intercept     score    class  \n",
       "0      15.0 -0.125  0.625        1.0  0.614808  neutral  \n",
       "1       9.0 -0.125  1.000        1.0  0.619522  neutral  \n",
       "2       1.0  0.000  0.000        1.0  0.448265  neutral  \n",
       "3       3.0  0.000  1.000        1.0  0.992207     good  \n",
       "4      18.0 -0.500  0.250        1.0  0.262286      bad  \n",
       "...     ...    ...    ...        ...       ...      ...  \n",
       "33483  60.0  0.000  0.500        1.0  0.560458  neutral  \n",
       "33484  60.0  0.000  0.500        1.0  0.486015  neutral  \n",
       "33485  60.0  0.000  0.500        1.0  0.486015  neutral  \n",
       "33486  60.0  0.000  0.500        1.0  0.486015  neutral  \n",
       "33487  54.0  0.000  0.500        1.0  0.477935  neutral  \n",
       "\n",
       "[33488 rows x 9 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nm_maxThres = [0.49494949] #<-- Value from training notebook\n",
    "vt_scoreLim = [1/3,2/3]\n",
    "\n",
    "comment_score = features_df.copy()\n",
    "comment_score['Intercept'] = 1.0\n",
    "comment_score[\"size\"]      = comment_score[\"size\"].astype('float64')\n",
    "\n",
    "comment_score[\"score\"] = logit_fit.predict(comment_score[['Intercept',\"mean\", \"sum\", \"max\"]])\n",
    "\n",
    "vt_good     = (comment_score[\"score\"] >= vt_scoreLim[1])\n",
    "vt_bad      = (comment_score[\"score\"] <= vt_scoreLim[0])\n",
    "vt_neutral  = (comment_score[\"score\"] > vt_scoreLim[0]) & (comment_score[\"score\"] < vt_scoreLim[1])\n",
    "\n",
    "#vt_good    = np.flatnonzero(list(vt_good.values))\n",
    "#vt_bad     = np.flatnonzero(list(vt_bad.values))\n",
    "#vt_neutral = np.flatnonzero(list(vt_neutral.values))\n",
    "\n",
    "comment_score[\"class\"] = 'na'\n",
    "comment_score.loc[vt_good.values,'class']    = 'good'\n",
    "comment_score.loc[vt_bad.values,'class']     = 'bad'\n",
    "comment_score.loc[vt_neutral.values,'class'] = 'neutral'\n",
    "\n",
    "comment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rootPost_id</th>\n",
       "      <th>parentPost_id</th>\n",
       "      <th>reponsePost_id</th>\n",
       "      <th>brand_username</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "      <th>likes</th>\n",
       "      <th>username</th>\n",
       "      <th>tokens</th>\n",
       "      <th>score</th>\n",
       "      <th>...</th>\n",
       "      <th>tendido</th>\n",
       "      <th>tenis</th>\n",
       "      <th>termo</th>\n",
       "      <th>toalla</th>\n",
       "      <th>tobillera</th>\n",
       "      <th>top</th>\n",
       "      <th>tutu</th>\n",
       "      <th>vestido</th>\n",
       "      <th>visera</th>\n",
       "      <th>zapato</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1947257691818809835</td>\n",
       "      <td>1.947258e+18</td>\n",
       "      <td>1.794235e+16</td>\n",
       "      <td>offcorss</td>\n",
       "      <td>as√≠ es un d√≠a para disfrutar  sana mente y con...</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>rosaliafaneite</td>\n",
       "      <td>as√≠ d√≠a disfrutar sana mente exito</td>\n",
       "      <td>0.614808</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1947952244502703605</td>\n",
       "      <td>1.947952e+18</td>\n",
       "      <td>1.801764e+16</td>\n",
       "      <td>offcorss</td>\n",
       "      <td>buenos d√≠as que precio tienen?</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>aleja.vasquez911</td>\n",
       "      <td>buenos d√≠as precio ?</td>\n",
       "      <td>0.619522</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1948073194162672935</td>\n",
       "      <td>1.948073e+18</td>\n",
       "      <td>1.791861e+16</td>\n",
       "      <td>offcorss</td>\n",
       "      <td>üéä</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>pactrii188</td>\n",
       "      <td>üéä</td>\n",
       "      <td>0.448265</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1948284380053077836</td>\n",
       "      <td>1.948284e+18</td>\n",
       "      <td>1.798609e+16</td>\n",
       "      <td>offcorss</td>\n",
       "      <td>hermosa mi sheshe</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>dalekeyboutique</td>\n",
       "      <td>hermosa sheshe</td>\n",
       "      <td>0.992207</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1948284380053077836</td>\n",
       "      <td>1.948284e+18</td>\n",
       "      <td>1.790035e+16</td>\n",
       "      <td>offcorss</td>\n",
       "      <td>cuanto cuesta el vestido de manga larga talla 14</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>3</td>\n",
       "      <td>delgadoa953</td>\n",
       "      <td>cuanto cuesta vestido manga larga talla 14</td>\n",
       "      <td>0.262286</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33483</th>\n",
       "      <td>2404696945357653802</td>\n",
       "      <td>1.791184e+16</td>\n",
       "      <td>1.793289e+16</td>\n",
       "      <td>politokids</td>\n",
       "      <td>@tina.benjumea üåü todos los tapabocas tienen un...</td>\n",
       "      <td>2020-09-23</td>\n",
       "      <td>0</td>\n",
       "      <td>politokids</td>\n",
       "      <td>@ tina.benjumea üåü tapabocas valor $ 10.900 , p...</td>\n",
       "      <td>0.560458</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33484</th>\n",
       "      <td>2404696945357653802</td>\n",
       "      <td>1.787722e+16</td>\n",
       "      <td>1.796018e+16</td>\n",
       "      <td>politokids</td>\n",
       "      <td>@anil_rizo üíõ todos los tapabocas tienen un val...</td>\n",
       "      <td>2020-09-23</td>\n",
       "      <td>0</td>\n",
       "      <td>politokids</td>\n",
       "      <td>@ anil_rizo üíõ tapabocas valor $ 10.900 , puede...</td>\n",
       "      <td>0.486015</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33485</th>\n",
       "      <td>2404696945357653802</td>\n",
       "      <td>1.790429e+16</td>\n",
       "      <td>1.786213e+16</td>\n",
       "      <td>politokids</td>\n",
       "      <td>üíõüíõ @paopao.martinezfigueroa  todos los tapaboc...</td>\n",
       "      <td>2020-09-23</td>\n",
       "      <td>0</td>\n",
       "      <td>politokids</td>\n",
       "      <td>üíõüíõ @ paopao.martinezfigueroa tapabocas valor $...</td>\n",
       "      <td>0.486015</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33486</th>\n",
       "      <td>2404696945357653802</td>\n",
       "      <td>1.785560e+16</td>\n",
       "      <td>1.788603e+16</td>\n",
       "      <td>politokids</td>\n",
       "      <td>@contreraszarateyamileth ‚òÄÔ∏è‚òÄÔ∏è todos los tapabo...</td>\n",
       "      <td>2020-09-23</td>\n",
       "      <td>0</td>\n",
       "      <td>politokids</td>\n",
       "      <td>@ contreraszarateyamileth ‚òÄÔ∏è‚òÄÔ∏è tapabocas valor...</td>\n",
       "      <td>0.486015</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33487</th>\n",
       "      <td>2404696945357653802</td>\n",
       "      <td>1.785799e+16</td>\n",
       "      <td>1.793346e+16</td>\n",
       "      <td>politokids</td>\n",
       "      <td>@laer1217  hola!!! todos los tapabocas tienen ...</td>\n",
       "      <td>2020-09-23</td>\n",
       "      <td>1</td>\n",
       "      <td>nataliazabala</td>\n",
       "      <td>@ laer1217 hola ! ! ! tapabocas valor $ 10.900...</td>\n",
       "      <td>0.477935</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33488 rows √ó 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               rootPost_id  parentPost_id  reponsePost_id brand_username  \\\n",
       "0      1947257691818809835   1.947258e+18    1.794235e+16       offcorss   \n",
       "1      1947952244502703605   1.947952e+18    1.801764e+16       offcorss   \n",
       "2      1948073194162672935   1.948073e+18    1.791861e+16       offcorss   \n",
       "3      1948284380053077836   1.948284e+18    1.798609e+16       offcorss   \n",
       "4      1948284380053077836   1.948284e+18    1.790035e+16       offcorss   \n",
       "...                    ...            ...             ...            ...   \n",
       "33483  2404696945357653802   1.791184e+16    1.793289e+16     politokids   \n",
       "33484  2404696945357653802   1.787722e+16    1.796018e+16     politokids   \n",
       "33485  2404696945357653802   1.790429e+16    1.786213e+16     politokids   \n",
       "33486  2404696945357653802   1.785560e+16    1.788603e+16     politokids   \n",
       "33487  2404696945357653802   1.785799e+16    1.793346e+16     politokids   \n",
       "\n",
       "                                                    text        time  likes  \\\n",
       "0      as√≠ es un d√≠a para disfrutar  sana mente y con...  2019-01-01      1   \n",
       "1                         buenos d√≠as que precio tienen?  2019-01-02      1   \n",
       "2                                                      üéä  2019-01-02      1   \n",
       "3                                      hermosa mi sheshe  2019-01-03      1   \n",
       "4       cuanto cuesta el vestido de manga larga talla 14  2019-01-03      3   \n",
       "...                                                  ...         ...    ...   \n",
       "33483  @tina.benjumea üåü todos los tapabocas tienen un...  2020-09-23      0   \n",
       "33484  @anil_rizo üíõ todos los tapabocas tienen un val...  2020-09-23      0   \n",
       "33485  üíõüíõ @paopao.martinezfigueroa  todos los tapaboc...  2020-09-23      0   \n",
       "33486  @contreraszarateyamileth ‚òÄÔ∏è‚òÄÔ∏è todos los tapabo...  2020-09-23      0   \n",
       "33487  @laer1217  hola!!! todos los tapabocas tienen ...  2020-09-23      1   \n",
       "\n",
       "               username                                             tokens  \\\n",
       "0        rosaliafaneite                 as√≠ d√≠a disfrutar sana mente exito   \n",
       "1      aleja.vasquez911                               buenos d√≠as precio ?   \n",
       "2            pactrii188                                                  üéä   \n",
       "3       dalekeyboutique                                     hermosa sheshe   \n",
       "4           delgadoa953         cuanto cuesta vestido manga larga talla 14   \n",
       "...                 ...                                                ...   \n",
       "33483        politokids  @ tina.benjumea üåü tapabocas valor $ 10.900 , p...   \n",
       "33484        politokids  @ anil_rizo üíõ tapabocas valor $ 10.900 , puede...   \n",
       "33485        politokids  üíõüíõ @ paopao.martinezfigueroa tapabocas valor $...   \n",
       "33486        politokids  @ contreraszarateyamileth ‚òÄÔ∏è‚òÄÔ∏è tapabocas valor...   \n",
       "33487     nataliazabala  @ laer1217 hola ! ! ! tapabocas valor $ 10.900...   \n",
       "\n",
       "          score  ... tendido  tenis  termo  toalla  tobillera  top  tutu  \\\n",
       "0      0.614808  ...       0      0      0       0          0    0     0   \n",
       "1      0.619522  ...       0      0      0       0          0    0     0   \n",
       "2      0.448265  ...       0      0      0       0          0    0     0   \n",
       "3      0.992207  ...       0      0      0       0          0    0     0   \n",
       "4      0.262286  ...       0      0      0       0          0    0     0   \n",
       "...         ...  ...     ...    ...    ...     ...        ...  ...   ...   \n",
       "33483  0.560458  ...       0      0      0       0          0    0     0   \n",
       "33484  0.486015  ...       0      0      0       0          0    0     0   \n",
       "33485  0.486015  ...       0      0      0       0          0    0     0   \n",
       "33486  0.486015  ...       0      0      0       0          0    0     0   \n",
       "33487  0.477935  ...       0      0      0       0          0    0     0   \n",
       "\n",
       "       vestido  visera  zapato  \n",
       "0            0       0       0  \n",
       "1            0       0       0  \n",
       "2            0       0       0  \n",
       "3            0       0       0  \n",
       "4            1       0       0  \n",
       "...        ...     ...     ...  \n",
       "33483        0       0       0  \n",
       "33484        0       0       0  \n",
       "33485        0       0       0  \n",
       "33486        0       0       0  \n",
       "33487        0       0       0  \n",
       "\n",
       "[33488 rows x 101 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_comments_scored = pd.merge(data_comments, comments_df[['tokens']], left_index = True, right_index=True)\n",
    "data_comments_scored = pd.merge(data_comments_scored, comment_score[['score','class']], left_index = True, right_index=True)\n",
    "data_comments_scored = pd.merge(data_comments_scored, products_df, left_index = True, right_index=True)\n",
    "data_comments_scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed files\n",
    "save_datapath = 'C:\\\\Users\\\\sapmn3\\\\Database\\\\OFFCORSS\\\\data\\\\data_clean'\n",
    "save_file = 'instagram_responses_scored'\n",
    "save_path = os.path.join(save_datapath, save_file + '.csv')\n",
    "\n",
    "data_comments_scored.to_csv(save_path, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
